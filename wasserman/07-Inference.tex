\section*{7. Models, Statistical Inference and Learning}\label{models-statistical-inference-and-learning}

\subsection*{7.2 Parametric and Nonparametric
Models}\label{parametric-and-nonparametric-models}

A \textbf{statistical model} is a set of distributions \(\mathfrak{F}\).

A \textbf{parametric model} is a set \(\mathfrak{F}\) that may be
parametrized by a finite number of parameters. For example, if we assume
that data comes from a normal distribution then

\[ \mathfrak{F} = \left\{ f(x; \mu, \sigma) = 
\frac{1}{\sigma\sqrt{\pi}} \exp \left\{ -\frac{1}{2\sigma^{2}} \left(x - \mu \right)^{2} \right\}, \; \; 
\mu \in \mathbb{R}, \; \sigma > 0
\right\} \]

In general, a parametric model takes the form

\[ \mathfrak{F} = \left\{ f(x; \theta) : \; \theta \in \Theta \right\} \]

where \(\theta\) is an unknown parameter that takes values in the
\textbf{parameter space} \(\Theta\).

If \(\theta\) is a vector and we are only interested in one component of
\(\theta\), we call the remaining parameters \textbf{nuisance
parameters}.

A \textbf{nonparametric model} is a set \(\mathfrak{F}\) that cannot be
parametrized by a finite number of parameters.

\paragraph{Some notation}\label{some-notation}

If \(\mathfrak{F} = \{ f(x; \theta) : \; \theta \in \Theta \}\) is a
parametric model, we write

\[\mathbb{P}_\theta(X \in A) = \int_A f(x; \theta)dx\]

\[\mathbb{E}_\theta(X \in A) = \int_A x f(x; \theta)dx\]

The subscript \(\theta\) indicates that the probability or expectation
is defined with respect to \(f(x; \theta)\); it does not mean we are
averaging over \(\theta\).

\subsection*{7.3 Fundamental Concepts in
Inference}\label{fundamental-concepts-in-inference}

\paragraph{7.3.1 Point estimation}\label{point-estimation}

Let \(X_{1}, \dots, X_{n}\) be \(n\) iid data points from some distribution
\(F\). A point estimator \(\hat{\theta_{n}}\) of a parameter \(\theta\) is
some function:

\[ \hat{\theta_{n}} = g(X_{1}, \dots, X_{n}) \]

We define

\[ \text{bias}(\hat{\theta_{n}}) = \mathbb{E}_\theta(\hat{\theta_{n}}) - \theta \]

to be the bias of \(\hat{\theta_{n}}\). We say that \(\hat{\theta_{n}}\) is
\textbf{unbiased} if $ \mathbb{E}\_\theta(\hat{\theta_{n}}) = 0 $.

A point estimator \(\hat{\theta_{n}}\) of a parameter \(\theta\) is
\textbf{consistent} if \(\hat{\theta_{n}} \xrightarrow{\text{P}} \theta\).

The distribution of \(\hat{\theta_{n}}\) is called the \textbf{sampling
distribution}.

The standard deviation of \(\hat{\theta_{n}}\) is called the
\textbf{standard error}, denoted by \(\text{se}\):

\[ \text{se} = \text{se}(\hat{\theta_{n}}) = \sqrt{\mathbb{V}(\hat{\theta_{n}})} \]

Often it is not possible to compute the standard error but usually we
can estimate the standard error. The estimated standard error is denoted
by \(\hat{\text{se}}\).

\textbf{Example}. Let \(X_{1}, \dots, X_{n} \sim \text{Bernoulli}(p)\) and
let \(\hat{p_{n}} = n^{-1} \sum_{i} X_{i}\). Then
\(\mathbb{E}(\hat{p_{n}}) = n^{-1} \sum_{i} \mathbb{E}(X_{i}) = p\) so
\(\hat{p_{n}}\) is unbiased. The standard error is
\(\text{se} = \sqrt{\mathbb{V}(\hat{p_{n}})} = \sqrt{p(1-p)/n}\). The
estimated standard error is
\(\hat{\text{se}} = \sqrt{\hat{p}(1 - \hat{p})/n}\).

The quality of a point estimate is sometimes assessed by the
\textbf{mean squared error}, or MSE, defined by:

\[ \text{MSE} = \mathbb{E}_\theta \left( \hat{\theta_{n}} - \theta \right)^{2} \]

\textbf{Theorem 7.8}. The MSE can be rewritten as:

\[ \text{MSE} = \text{bias}(\hat{\theta_{n}})^{2} + \mathbb{V}_\theta(\hat{\theta_{n}}) \]

\textbf{Proof}. Let
\(\bar{\theta_{n}} = \mathbb{E}_\theta(\hat{\theta_{n}})\). Then

\begin{align*}
\mathbb{E}_\theta(\hat{\theta_{n}} - \theta)^{2} & = \mathbb{E}_\theta(\hat{\theta_{n}} - \bar{\theta_{n}} + \bar{\theta_{n}} - \theta)^{2} \\
&=  \mathbb{E}_\theta(\hat{\theta_{n}} - \bar{\theta_{n}})^{2}
  + 2 (\bar{\theta_{n}} - \theta) \mathbb{E}_\theta(\hat{\theta_{n}} - \bar{\theta_{n}})
  + \mathbb{E}_\theta(\hat{\theta_{n}} - \theta)^{2} \\
&= (\bar{\theta_{n}} - \theta)^{2} + \mathbb{E}_\theta(\hat{\theta_{n}} - \bar{\theta_{n}})^{2} \\
&= \text{bias}^{2} + \mathbb{V}_\theta(\hat{\theta_{n}})
\end{align*}

\textbf{Theorem 7.9}. If \(\text{bias} \rightarrow 0\) and
\(\text{se} \rightarrow 0\) as \(n \rightarrow \infty\) then
\(\hat{\theta_{n}}\) is consistent, that is,
\(\hat{\theta_{n}} \xrightarrow{\text{P}} \theta\).

\textbf{Proof}. If \(\text{bias} \rightarrow 0\) and
\(\text{se} \rightarrow 0\) then, by Theorem 7.8,
\(\text{MSE} \rightarrow 0\). It follows that
\(\hat{\theta_{n}} \xrightarrow{\text{qm}} \theta\) -- and quadratic mean
convergence implies probability convergence.

An estimator is \textbf{asymptotically Normal} if

\[ \frac{\hat{\theta_{n}} - \theta}{\text{se}} \leadsto N(0, 1) \]

\paragraph{7.3.2 Confidence sets}\label{confidence-sets}

A \(1 - \alpha\) \textbf{confidence interval} for a parameter \(\theta\)
is an interval \(C_{n} = (a, b)\) where \(a = a(X_{1}, \dots, X_{n})\) and
\(b = b(X_{1}, \dots, _{n})\) are functions of the data such that

\[\mathbb{P}_\theta(\theta \in C_{n}) \geq 1 - \alpha, \;\; \text{for all } \theta \in \Theta\]

In words, \((a, b)\) traps \(\theta\) with probability \(1 - \alpha\).
We call \(1 - \alpha\) the \textbf{coverage} of the confidence interval.

Note: \textbf{\(C_{n}\) is random and \(\theta\) is fixed!}

If \(\theta\) is a vector then we use a confidence set (such as a sphere
or ellipse) instead of an interval.

Point estimators often have a limiting Normal distribution, meaning
\(\hat{\theta_{n}} \approx N(\theta, \hat{\text{se}}^{2})\). In this case we
can construct (approximate) confidence intervals as follows:

\textbf{Theorem 7.14 (Normal-based Confidence Interval)}. Suppose that
\(\hat{\theta_{n}} \approx N(\theta, \hat{\text{se}}^{2})\). Let \(\Phi\) be
the CDF of a standard Normal and let
\(z_{\alpha/2} = \Phi^{-1}\left(1 - (\alpha / 2)\right)\), that is,
\(\mathbb{P}(Z > z_{\alpha/2}) = \alpha/2\) and
\(\mathbb{P}(-z_{\alpha/2} < Z < z_{alpha/2}) = 1 - \alpha\) where
\(Z \sim N(0, 1)\). Let

\[ C_{n} = \left(\hat{\theta_{n}} - z_{\alpha/2} \hat{\text{se}}, \; \hat{\theta_{n}} + z_{\alpha/2} \hat{\text{se}}\right) \]

Then

\[ \mathbb{P}_\theta(\theta \in C_{n}) \rightarrow 1 - \alpha \].

\textbf{Proof}.

Let \(Z_{n} = (\hat{\theta_{n}} - \theta) / \hat{\text{se}}\). By assumption
\(Z_{n} \leadsto Z \sim N(0, 1)\). Hence,

\begin{align*}
\mathbb{P}_\theta(\theta \in C_{n}) 
& = \mathbb{P}_\theta \left(\hat{\theta_{n}} - z_{\alpha/2} \hat{\text{se}} < \theta < \hat{\theta_{n}} + z_{\alpha/2} \hat{\text{se}} \right) \\
& = \mathbb{P}_\theta \left(-z_{\alpha/2} < \frac{\hat{\theta_{n}} - \theta}{\hat{\text{se}}} < z_{\alpha/2} \right) \\
& \rightarrow \mathbb{P}\left(-z_{\alpha/2} < Z < z_{\alpha/2}\right) \\
&= 1 - \alpha
\end{align*}

\paragraph{7.3.3 Hypothesis Testing}\label{hypothesis-testing}

In \textbf{hypothesis testing}, we start with some default theory --
called a \textbf{null hypothesis} -- and we ask if the data provide
sufficient evidence to reject the theory. If not we retain the null
hypothesis.

\subsection*{7.5 Technical Appendix}

\begin{itemize}[tightlist]
\item
  Our definition of confidence interval requires that
  \(\mathbb{P}_\theta(\theta \in C_{n}) \geq 1 - \alpha\) for all
  \(\theta \in \Theta\).
\item
  A \textbf{pointwise asymptotic} confidence interval requires that
  \(\lim \inf_{n \rightarrow \infty} \mathbb{P}_\theta(\theta \in C_{n}) \geq 1 - \alpha\)
  for all \(\theta \in \Theta\).
\item
  An \textbf{uniform asymptotic} confidence interval requires that
  \(\lim \inf_{n \rightarrow \infty} \inf{\theta \in \Theta} \mathbb{P}_\theta(\theta \in C_{n}) \geq 1 - \alpha\).
\end{itemize}

The approximate Normal-based interval is a pointwise asymptotic
confidence interval. In general, it might not be a uniform asymptotic
confidence interval.

