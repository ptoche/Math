\section*{7. Models, Statistical Inference and Learning}\label{models-statistical-inference-and-learning}

\subsection*{7.2 Parametric and Nonparametric
Models}\label{parametric-and-nonparametric-models}
A \textbf{statistical model} is a set of distributions \(\mathfrak{F}\).
A \textbf{parametric model} is a set \(\mathfrak{F}\) that may be
parametrized by a finite number of parameters. For example, if we assume
that data comes from a normal distribution then
\[
\mathfrak{F} = \left\{ f(x; \mu, \sigma) = 
\frac{1}{\sigma\sqrt{\pi}} \exp \left\{ -\frac{1}{2\sigma^{2}} \left(x - \mu \right)^{2} \right\}, \; \; 
\mu \in \R, \; \sigma > 0
\right\}
\]
In general, a parametric model takes the form
\[
\mathfrak{F} = \left\{ f(x; \theta) : \; \theta \in \Theta \right\}
\]
where \(\theta\) is an unknown parameter that takes values in the
\textbf{parameter space} \(\Theta\).
If \(\theta\) is a vector and we are only interested in one component of
\(\theta\), we call the remaining parameters \textbf{nuisance
parameters}.
A \textbf{nonparametric model} is a set \(\mathfrak{F}\) that cannot be
parametrized by a finite number of parameters.
\paragraph{Some notation}\label{some-notation}
If \(\mathfrak{F} = \{ f(x; \theta) : \; \theta \in \Theta \}\) is a
parametric model, we write
\[
\PROB_\theta(X \in A) = \int_A f(x; \theta)dx
\]
\[
\EXP_{\theta}(X \in A) = \int_A x f(x; \theta)dx
\]
The subscript \(\theta\) indicates that the probability or expectation
is defined with respect to \(f(x; \theta)\); it does not mean we are
averaging over \(\theta\).

\subsection*{7.3 Fundamental Concepts in
Inference}\label{fundamental-concepts-in-inference}
\paragraph{7.3.1 Point estimation}\label{point-estimation}
Let \(X_{1}, \dots, X_{n}\) be \(n\) iid data points from some distribution
\(F\). A point estimator \(\hat{\theta}_{n}\) of a parameter \(\theta\) is
some function:
\[
\hat{\theta}_{n} = g(X_{1}, \dots, X_{n})
\]
We define
\[
\text{bias}(\hat{\theta}_{n}) = \EXP_{\theta}(\hat{\theta}_{n}) - \theta
\]
to be the bias of \(\hat{\theta}_{n}\). We say that \(\hat{\theta}_{n}\) is
\textbf{unbiased} if $ \EXP\_\theta(\hat{\theta}_{n}) = 0 $.
A point estimator \(\hat{\theta}_{n}\) of a parameter \(\theta\) is
\textbf{consistent} if \(\hat{\theta}_{n} \xrightarrow{\textrm{P}} \theta\).
The distribution of \(\hat{\theta}_{n}\) is called the \textbf{sampling
distribution}.
The standard deviation of \(\hat{\theta}_{n}\) is called the
\textbf{standard error}, denoted by \(\SE \):
\[
\SE = \SE (\hat{\theta}_{n}) = \sqrt{\VAR(\hat{\theta}_{n})}
\]
Often it is not possible to compute the standard error but usually we
can estimate the standard error. The estimated standard error is denoted
by \(\widehat{\SE}\).
\textbf{Example}. Let \(X_{1}, \dots, X_{n} \sim \text{Bernoulli}(p)\) and
let \(\hat{p}_{n} = n^{-1} \sum_{i} X_{i}\). Then
\(\EXP(\hat{p}_{n}) = n^{-1} \sum_{i} \EXP(X_{i}) = p\) so
\(\hat{p}_{n}\) is unbiased. The standard error is
\(\SE = \sqrt{\VAR(\hat{p}_{n})} = \sqrt{p(1-p)/n}\). The
estimated standard error is
\(\widehat{\SE} = \sqrt{\hat{p}(1 - \hat{p})/n}\).
The quality of a point estimate is sometimes assessed by the
\textbf{mean squared error}, or MSE, defined by:
\[
\MSE = \EXP_{\theta} \left( \hat{\theta}_{n} - \theta \right)^{2}
\]

\textbf{Theorem 7.8}. The MSE can be rewritten as:
\[
\MSE = \text{bias}(\hat{\theta}_{n})^{2} + \VAR_\theta(\hat{\theta}_{n})
\]
\textbf{Proof}. Let
\(\bar{\theta}_{n} = \EXP_{\theta}(\hat{\theta}_{n})\). Then
\begin{align*}
\EXP_{\theta}(\hat{\theta}_{n} - \theta)^{2} & = \EXP_{\theta}(\hat{\theta}_{n} - \bar{\theta}_{n} + \bar{\theta}_{n} - \theta)^{2} \\
&=  \EXP_{\theta}(\hat{\theta}_{n} - \bar{\theta}_{n})^{2}
  + 2 (\bar{\theta}_{n} - \theta) \EXP_{\theta}(\hat{\theta}_{n} - \bar{\theta}_{n})
  + \EXP_{\theta}(\hat{\theta}_{n} - \theta)^{2} \\
&= (\bar{\theta}_{n} - \theta)^{2} + \EXP_{\theta}(\hat{\theta}_{n} - \bar{\theta}_{n})^{2} \\
&= \text{bias}^{2} + \VAR_\theta(\hat{\theta}_{n})
\end{align*}

\textbf{Theorem 7.9}. If \(\text{bias} \rightarrow 0\) and
\(\SE \rightarrow 0\) as \(n \rightarrow \infty\) then
\(\hat{\theta}_{n}\) is consistent, that is,
\(\hat{\theta}_{n} \xrightarrow{\textrm{P}} \theta\).
\textbf{Proof}. If \(\text{bias} \rightarrow 0\) and
\(\SE \rightarrow 0\) then, by Theorem 7.8,
\(\MSE \rightarrow 0\). It follows that
\(\hat{\theta}_{n} \xrightarrow{\text{qm}} \theta\) -- and quadratic mean
convergence implies probability convergence.
An estimator is \textbf{asymptotically Normal} if
\[
\frac{\hat{\theta}_{n} - \theta}{\SE } \leadsto N(0, 1)
\]
\paragraph{7.3.2 Confidence sets}\label{confidence-sets}
A \(1 - \alpha\) \textbf{confidence interval} for a parameter \(\theta\)
is an interval \(C_{n} = (a, b)\) where \(a = a(X_{1}, \dots, X_{n})\) and
\(b = b(X_{1}, \dots, _{n})\) are functions of the data such that
\[
\PROB_\theta(\theta \in C_{n}) \geq 1 - \alpha, \;\; \text{for all } \theta \in \Theta
\]
In words, \((a, b)\) traps \(\theta\) with probability \(1 - \alpha\).
We call \(1 - \alpha\) the \textbf{coverage} of the confidence interval.
Note: \textbf{\(C_{n}\) is random and \(\theta\) is fixed!}
If \(\theta\) is a vector then we use a confidence set (such as a sphere
or ellipse) instead of an interval.
Point estimators often have a limiting Normal distribution, meaning
\(\hat{\theta}_{n} \approx N(\theta, \widehat{\SE}^{2})\). In this case we
can construct (approximate) confidence intervals as follows:

\textbf{Theorem 7.14 (Normal-based Confidence Interval)}. Suppose that
\(\hat{\theta}_{n} \approx N(\theta, \widehat{\SE}^{2})\). Let \(\Phi\) be
the CDF of a standard Normal and let
\(z_{\alpha/2} = \Phi^{-1}\left(1 - (\alpha / 2)\right)\), that is,
\(\PROB(Z > z_{\alpha/2}) = \alpha/2\) and
\(\PROB(-z_{\alpha/2} < Z < z_{alpha/2}) = 1 - \alpha\) where
\(Z \sim N(0, 1)\). Let
\[
C_{n} = \left(\hat{\theta}_{n} - z_{\alpha/2} \widehat{\SE}, \; \hat{\theta}_{n} + z_{\alpha/2} \widehat{\SE}\right)
\]
Then
\[
\PROB_\theta(\theta \in C_{n}) \rightarrow 1 - \alpha
\].
\textbf{Proof}.
Let \(Z_{n} = (\hat{\theta}_{n} - \theta) / \widehat{\SE}\). By assumption
\(Z_{n} \leadsto Z \sim N(0, 1)\). Hence,
\begin{align*}
\PROB_\theta(\theta \in C_{n}) 
& = \PROB_\theta \left(\hat{\theta}_{n} - z_{\alpha/2} \widehat{\SE} < \theta < \hat{\theta}_{n} + z_{\alpha/2} \widehat{\SE} \right) \\
& = \PROB_\theta \left(-z_{\alpha/2} < \frac{\hat{\theta}_{n} - \theta}{\widehat{\SE}} < z_{\alpha/2} \right) \\
& \rightarrow \PROB\left(-z_{\alpha/2} < Z < z_{\alpha/2}\right) \\
&= 1 - \alpha
\end{align*}
\paragraph{7.3.3 Hypothesis Testing}\label{hypothesis-testing}
In \textbf{hypothesis testing}, we start with some default theory --
called a \textbf{null hypothesis} -- and we ask if the data provide
sufficient evidence to reject the theory. If not we retain the null
hypothesis.

\subsection*{7.5 Technical Appendix}
\begin{itemize}[tightlist]
\item
  Our definition of confidence interval requires that
  \(\PROB_\theta(\theta \in C_{n}) \geq 1 - \alpha\) for all
  \(\theta \in \Theta\).
\item
  A \textbf{pointwise asymptotic} confidence interval requires that
  \(\lim \inf_{n \rightarrow \infty} \PROB_\theta(\theta \in C_{n}) \geq 1 - \alpha\)
  for all \(\theta \in \Theta\).
\item
  An \textbf{uniform asymptotic} confidence interval requires that
  \(\lim \inf_{n \rightarrow \infty} \inf{\theta \in \Theta} \PROB_\theta(\theta \in C_{n}) \geq 1 - \alpha\).
\end{itemize}
The approximate Normal-based interval is a pointwise asymptotic
confidence interval. In general, it might not be a uniform asymptotic
confidence interval.
